{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AV_SW_hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZGlxNWGM1Wq"
      },
      "source": [
        "##Importing all the necessary modules\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mping\n",
        "import numpy as np\n",
        "import tensorflow.keras as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzRsaLVPW_7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0011efb-0d96-4528-9d85-9ffa7a687d74"
      },
      "source": [
        "##Connecting google colab to my drive (omitted in the case of running it locally)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OvlAJJ-Vp1T",
        "outputId": "a34e474f-4640-4366-f01e-9e32332c463f"
      },
      "source": [
        "#Creating the training set\n",
        "##Unzipping the zipped training_set sent by you\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/trainset.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall(\"/content/drive/MyDrive\")\n",
        "  print('finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rBupSGBWSXQ",
        "outputId": "877aa3cf-0946-447f-94f9-ab5051813bc5"
      },
      "source": [
        "##Adding my image folder (new class of images) to the last sub folder of training_set\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "fromDirectory = \"/content/drive/MyDrive/0015\"\n",
        "toDirectory = \"/content/drive/MyDrive/trainset/0014\"\n",
        "\n",
        "copy_tree(fromDirectory, toDirectory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/trainset/0014/0015_003/Morgan-Freeman.jpg',\n",
              " '/content/drive/MyDrive/trainset/0014/0015_003/t2_MF-Headshot-030813.jpg',\n",
              " '/content/drive/MyDrive/trainset/0014/0015_003/MV5BMTc0MDMyMzI2OF5BMl5BanBnXkFtZTcwMzM2OTk1MQ@@._V1_UX214_CR0,0,214,317_AL_.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFI0jlWYKTt"
      },
      "source": [
        "##The training set provided had subfolders within subfolders which were to be utilised. Therefore, defining a function to get the paths of all the subfolders(classes) in a list\n",
        "def list_of_final_folders(dir):\n",
        " items=[]\n",
        " wrong_folder_list= os.listdir(dir)\n",
        " for element in wrong_folder_list:\n",
        "      element_path= dir+\"/\"+element\n",
        "      right_folder_list=(os.listdir(element_path))\n",
        "      for index in right_folder_list:\n",
        "        items.append(os.path.join(element_path+\"/\", index))\n",
        " return items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzxHR3YX0gd"
      },
      "source": [
        "##Defining a function to load images from each folder\n",
        "def load_images_from_folder(folder):\n",
        "    raw_images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            raw_images.append(img)\n",
        "    return raw_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbvYS_nAYjMs"
      },
      "source": [
        "##Defining a variable to use the Cascade Classifier from the OpenCV predefined face extraction .xml file for face extraction\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDSPWPB4Y5uv"
      },
      "source": [
        "##Defining the parent directory where all the images will be stored within sub directories\n",
        "parent_dir=\"/content/drive/MyDrive/pre_processed_images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moHkjjh-ZKuC"
      },
      "source": [
        "##Using the function defined above to get the list of paths to the folders which contain the images\n",
        "list_of_folders= list_of_final_folders(\"/content/drive/MyDrive/trainset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ERbdVxcZylw"
      },
      "source": [
        "##Finally running each image through the face extraction and saving them in subfolders with class numbers\n",
        "for i in range(len(list_of_folders)):\n",
        " directory = 'Class'+str(i)+\"/\"\n",
        " path = os.path.join(parent_dir, directory)\n",
        " os.mkdir(path)\n",
        " raw_images= load_images_from_folder(list_of_folders[i])\n",
        " for j in range(len(raw_images)):\n",
        "   faces= face_cascade.detectMultiScale(raw_images[j])\n",
        "   if len(faces)==1:\n",
        "     for x, y, w, h in faces:\n",
        "       actual_image= raw_images[j][y:y+h, x:x+w]\n",
        "       filename= parent_dir+ directory + \"00\" + str(j) + '_actual_image.jpg'\n",
        "       cv2.imwrite(filename, actual_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUECaLZJsuvP",
        "outputId": "5fced438-a687-4a95-b6c1-3b8ef33c77a1"
      },
      "source": [
        "#Using ImageDataGenerator for image augmentation\n",
        "train_datagen= ImageDataGenerator(rescale=1./255,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "training_set= train_datagen.flow_from_directory('/content/drive/MyDrive/pre_processed_images', target_size=(128,128), batch_size=32, class_mode= 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3055 images belonging to 1013 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFVHc9by7Q6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf2af837-43db-40e7-d61a-8eae3708adaa"
      },
      "source": [
        "#Checking the accuracy of ANN models for an inputed number of maximum layers \n",
        "#Losses and accuracy are saved in a list for an increasing number of 32 node dense layers and decreasing number of 64 node dense layers assuming number of layers as 1, 2... till the maximum number of layers is reached\n",
        "#The losses and accuracy are appended and saved in a list. Then plotted assuming labels as 1, 2, 3.. (6 labels for 4 maximum layers considering the combinations, 10 layers for 5 maximum layers considering the combination, etc.)\n",
        "accuracy=[]\n",
        "loss=[]\n",
        "n=input()\n",
        "n=int(n)\n",
        "for i in range(1,n):\n",
        " for j in range(i):\n",
        "    model= tf.models.Sequential()\n",
        "    model.add(tf.layers.Flatten())\n",
        "    for m in range(i-j):\n",
        "     model.add(tf.layers.Dense(32, activation=\"relu\"))\n",
        "    for m in range(j):\n",
        "     model.add(tf.layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(tf.layers.Dense(1013, activation=\"softmax\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "    ann_model= model.fit(training_set, epochs=20, steps_per_epoch= 3055//32)\n",
        "    l=ann_model.history['loss'][19]\n",
        "    a=ann_model.history['acc'][19]\n",
        "    loss.append(l)\n",
        "    accuracy.append(a)\n",
        "print(loss)\n",
        "print(accuracy)\n",
        "\n",
        "##Plotting the loss and accuracy graphs\n",
        "sum=0\n",
        "for i in range(1,n):\n",
        "  sum=sum+i\n",
        "def createlistoflabels(g): \n",
        "    return list(range(1, g+1))\n",
        "labels= createlistoflabels(sum)\n",
        "plt.scatter(labels, loss)\n",
        "plt.scatter(labels, accuracy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 17s 183ms/step - loss: 6.9829 - acc: 0.0013\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 18s 184ms/step - loss: 6.9096 - acc: 0.0026\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 17s 181ms/step - loss: 6.9025 - acc: 0.0030\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8960 - acc: 0.0017\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8901 - acc: 0.0030\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8841 - acc: 0.0036\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.8790 - acc: 0.0026\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8736 - acc: 0.0036\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.8688 - acc: 0.0036\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8643 - acc: 0.0036\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 17s 184ms/step - loss: 6.8601 - acc: 0.0036\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.8560 - acc: 0.0036\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.8521 - acc: 0.0036\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.8475 - acc: 0.0036\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8444 - acc: 0.0036\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.8414 - acc: 0.0036\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 6.8381 - acc: 0.0033\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 6.8338 - acc: 0.0036\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 17s 181ms/step - loss: 6.8310 - acc: 0.0036\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8285 - acc: 0.0036\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.9953 - acc: 0.0023\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.9082 - acc: 0.0030\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8922 - acc: 0.0026\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.8711 - acc: 0.0036\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.8492 - acc: 0.0036\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.8303 - acc: 0.0036\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.8145 - acc: 0.0036\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.8023 - acc: 0.0036\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 6.7908 - acc: 0.0036\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7837 - acc: 0.0030\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 17s 181ms/step - loss: 6.7775 - acc: 0.0026\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7719 - acc: 0.0036\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7676 - acc: 0.0036\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7650 - acc: 0.0036\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 18s 187ms/step - loss: 6.7638 - acc: 0.0036\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 17s 181ms/step - loss: 6.7642 - acc: 0.0036\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.7624 - acc: 0.0017\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.7611 - acc: 0.0023\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 17s 178ms/step - loss: 6.7610 - acc: 0.0026\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7607 - acc: 0.0026\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.9538 - acc: 0.0017\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.9088 - acc: 0.0026\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.9051 - acc: 9.9239e-04\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.8784 - acc: 0.0026\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.8534 - acc: 0.0026\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 17s 183ms/step - loss: 6.8281 - acc: 0.0033\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.8048 - acc: 0.0030\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7904 - acc: 0.0026\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7807 - acc: 9.9239e-04\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7739 - acc: 0.0023\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7704 - acc: 0.0017\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 17s 181ms/step - loss: 6.7700 - acc: 0.0036\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 18s 188ms/step - loss: 6.7691 - acc: 0.0036\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7666 - acc: 0.0036\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7664 - acc: 0.0020\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7655 - acc: 0.0030\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7657 - acc: 0.0036\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 6.7640 - acc: 0.0033\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7636 - acc: 0.0030\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 17s 179ms/step - loss: 6.7640 - acc: 0.0036\n",
            "[6.828473091125488, 6.760734558105469, 6.7640380859375]\n",
            "[0.0036387694999575615, 0.0026463777758181095, 0.0036387694999575615]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhPsprWzkBNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68a08778-9228-4454-a522-e1095a68b3fc"
      },
      "source": [
        "#Checking the accuracy of CNN models for an inputed number of layers. Losses and accuracy are saved in a list for \n",
        "#Losses and accuracy are saved in a list for a decreasing number of convoluted layers with 64 filters and an increasing number of convoluted layers with 128 filters for each number of layers=1, 2,..till maximum number of layers is reached\n",
        "#The losses and accuracy are appended and saved in a list. Then plotted assuming labels as 1, 2, 3.. (6 labels for 4 maximum layers considering the combinations, 10 layers for 5 maximum layers considering the combination, etc.)\n",
        "#The filter size is kept constant for the convoluted layers and the pooling layers as I tried it and there was not much increase in accuracy\n",
        "accuracy=[]\n",
        "loss=[]\n",
        "n=input()\n",
        "n=int(n)\n",
        "for i in range(1,n):\n",
        " for j in range(i):\n",
        "  model = Sequential();\n",
        "  model.add(Conv2D(32,(3,3),input_shape=(128,128,3),activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  for m in range(i-j):                                                   \n",
        "   model.add(Conv2D(64, (3,3), activation= 'relu'))\n",
        "   model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "   model.add(Dropout(0.3))\n",
        "  for m in range(j):\n",
        "   model.add(Conv2D(128, (3,3), activation= 'relu'))\n",
        "   model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "   model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(tf.layers.Dense(1013, activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "  cnn_model= model.fit(training_set, epochs=20, steps_per_epoch= 3055//32)\n",
        "  l=cnn_model.history['loss'][19]\n",
        "  a=cnn_model.history['acc'][19]\n",
        "  loss.append(l)\n",
        "  accuracy.append(a)\n",
        "print(loss)\n",
        "print(accuracy)\n",
        "\n",
        "##Plotting the loss and accuracy graphs\n",
        "sum=0\n",
        "for i in range(1,n):\n",
        "  sum=sum+i\n",
        "def createlistoflabels(g): \n",
        "    return list(range(1, g+1))\n",
        "labels= createlistoflabels(sum)\n",
        "plt.scatter(labels, loss)\n",
        "plt.scatter(labels, accuracy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "95/95 [==============================] - 124s 1s/step - loss: 7.3845 - acc: 9.9239e-04\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 6.8001 - acc: 0.0043\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 6.5040 - acc: 0.0179\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 6.1223 - acc: 0.0370\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 5.6557 - acc: 0.0751\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 5.0901 - acc: 0.1379\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 4.4845 - acc: 0.2170\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 3.9650 - acc: 0.2957\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 3.3438 - acc: 0.3814\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 3.0228 - acc: 0.4204\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 2.5231 - acc: 0.5045\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 2.3027 - acc: 0.5491\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.9983 - acc: 0.5925\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.6485 - acc: 0.6580\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.4027 - acc: 0.7066\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.3396 - acc: 0.7172\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.1370 - acc: 0.7499\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 124s 1s/step - loss: 1.0011 - acc: 0.7777\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 0.8727 - acc: 0.8108\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 121s 1s/step - loss: 0.7419 - acc: 0.8290\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 96s 1s/step - loss: 6.9294 - acc: 0.0030\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 96s 1s/step - loss: 6.8846 - acc: 0.0023\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 95s 1000ms/step - loss: 6.8347 - acc: 0.0053\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 95s 999ms/step - loss: 6.7702 - acc: 0.0046\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 95s 998ms/step - loss: 6.7079 - acc: 0.0053\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 95s 998ms/step - loss: 6.6118 - acc: 0.0099\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 95s 997ms/step - loss: 6.4429 - acc: 0.0136\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 95s 998ms/step - loss: 6.2060 - acc: 0.0205\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 95s 997ms/step - loss: 5.8021 - acc: 0.0473\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 95s 998ms/step - loss: 5.3706 - acc: 0.0903\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 95s 1s/step - loss: 4.8649 - acc: 0.1485\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 95s 1s/step - loss: 4.2725 - acc: 0.2200\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 95s 1s/step - loss: 3.7602 - acc: 0.2851\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 95s 999ms/step - loss: 3.2626 - acc: 0.3669\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 95s 1s/step - loss: 2.7884 - acc: 0.4340\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 99s 1s/step - loss: 2.5730 - acc: 0.4767\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 95s 1s/step - loss: 2.2569 - acc: 0.5306\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 95s 1000ms/step - loss: 2.0540 - acc: 0.5673\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 95s 1000ms/step - loss: 1.7789 - acc: 0.6083\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 95s 997ms/step - loss: 1.6447 - acc: 0.6378\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 6.9334 - acc: 0.0013\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 6.8264 - acc: 0.0036\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 6.6712 - acc: 0.0103\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 6.4489 - acc: 0.0129\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 115s 1s/step - loss: 6.1092 - acc: 0.0314\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 113s 1s/step - loss: 5.7210 - acc: 0.0569\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 115s 1s/step - loss: 5.2031 - acc: 0.1012\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 116s 1s/step - loss: 4.7791 - acc: 0.1383\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 4.2125 - acc: 0.2144\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 3.7498 - acc: 0.2908\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 3.3443 - acc: 0.3311\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 2.8886 - acc: 0.4171\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 115s 1s/step - loss: 2.6134 - acc: 0.4479\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 2.3741 - acc: 0.4909\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 2.0666 - acc: 0.5528\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 1.8739 - acc: 0.5971\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 1.6982 - acc: 0.6153\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 118s 1s/step - loss: 1.5083 - acc: 0.6431\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 1.3346 - acc: 0.6917\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 114s 1s/step - loss: 1.2219 - acc: 0.7155\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 90s 947ms/step - loss: 6.9278 - acc: 0.0020\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 89s 939ms/step - loss: 6.8864 - acc: 0.0017\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 90s 952ms/step - loss: 6.8126 - acc: 0.0023\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 91s 955ms/step - loss: 6.7982 - acc: 0.0017\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 91s 958ms/step - loss: 6.7715 - acc: 0.0040\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 89s 941ms/step - loss: 6.7456 - acc: 0.0023\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 89s 934ms/step - loss: 6.6590 - acc: 0.0076\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 89s 936ms/step - loss: 6.4939 - acc: 0.0112\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 89s 933ms/step - loss: 6.3186 - acc: 0.0179\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 89s 934ms/step - loss: 6.0610 - acc: 0.0288\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 89s 937ms/step - loss: 5.7313 - acc: 0.0506\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 89s 934ms/step - loss: 5.4539 - acc: 0.0721\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 89s 933ms/step - loss: 5.0379 - acc: 0.1042\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 89s 939ms/step - loss: 4.7491 - acc: 0.1360\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 89s 938ms/step - loss: 4.4035 - acc: 0.1793\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 92s 972ms/step - loss: 4.0690 - acc: 0.2220\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 89s 934ms/step - loss: 3.7621 - acc: 0.2584\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 89s 939ms/step - loss: 3.4926 - acc: 0.2994\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 89s 939ms/step - loss: 3.2721 - acc: 0.3245\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 89s 939ms/step - loss: 2.9504 - acc: 0.3791\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 94s 994ms/step - loss: 6.9319 - acc: 3.3080e-04\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 94s 991ms/step - loss: 6.8686 - acc: 0.0036\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 93s 983ms/step - loss: 6.8145 - acc: 0.0036\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 93s 981ms/step - loss: 6.7847 - acc: 0.0023\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 93s 976ms/step - loss: 6.7657 - acc: 0.0036\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 93s 974ms/step - loss: 6.7223 - acc: 0.0053\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 93s 976ms/step - loss: 6.6444 - acc: 0.0040\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 93s 977ms/step - loss: 6.5824 - acc: 0.0046\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 93s 975ms/step - loss: 6.4810 - acc: 0.0089\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 93s 976ms/step - loss: 6.3929 - acc: 0.0109\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 93s 976ms/step - loss: 6.2952 - acc: 0.0139\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 96s 1s/step - loss: 6.0935 - acc: 0.0261\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 93s 981ms/step - loss: 5.8525 - acc: 0.0294\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 93s 981ms/step - loss: 5.5269 - acc: 0.0605\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 94s 993ms/step - loss: 5.2229 - acc: 0.0867\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 93s 980ms/step - loss: 4.8963 - acc: 0.1287\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 93s 981ms/step - loss: 4.5510 - acc: 0.1515\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 93s 980ms/step - loss: 4.2435 - acc: 0.1833\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 93s 979ms/step - loss: 3.9584 - acc: 0.2190\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 93s 978ms/step - loss: 3.6378 - acc: 0.2686\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 110s 1s/step - loss: 6.9293 - acc: 6.6159e-04\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.8917 - acc: 0.0013\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.8334 - acc: 0.0026\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 105s 1s/step - loss: 6.8020 - acc: 0.0026\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 105s 1s/step - loss: 6.7823 - acc: 0.0023\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.7470 - acc: 0.0046\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.6509 - acc: 0.0040\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.5439 - acc: 0.0073\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.4247 - acc: 0.0106\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 105s 1s/step - loss: 6.2733 - acc: 0.0202\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 6.1057 - acc: 0.0311\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 105s 1s/step - loss: 5.8741 - acc: 0.0400\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 109s 1s/step - loss: 5.6151 - acc: 0.0566\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 5.3334 - acc: 0.0705\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 5.1360 - acc: 0.0959\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 108s 1s/step - loss: 4.8275 - acc: 0.1178\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 4.6108 - acc: 0.1340\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 109s 1s/step - loss: 4.3708 - acc: 0.1657\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 4.1366 - acc: 0.1856\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 106s 1s/step - loss: 3.9488 - acc: 0.2206\n",
            "[0.7418767213821411, 1.6447250843048096, 1.2219470739364624, 2.9504482746124268, 3.6377599239349365, 3.948848009109497]\n",
            "[0.8289778232574463, 0.6377770304679871, 0.7155143618583679, 0.37909361720085144, 0.26860734820365906, 0.22064174711704254]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkaocH24tR5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077eca2a-c8f2-43ac-9779-5fb817def230"
      },
      "source": [
        "##Training the most accurate model from the graph\r\n",
        "model = Sequential();\r\n",
        "model.add(Conv2D(32,(3,3),input_shape=(128,128,3),activation = 'relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Conv2D(64, (3,3), activation= 'relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(tf.layers.Dense(1013, activation=\"softmax\"))\r\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\r\n",
        "model.fit(training_set, epochs=30, steps_per_epoch= 3055//32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "95/95 [==============================] - 121s 1s/step - loss: 7.1605 - acc: 3.3080e-04\n",
            "Epoch 2/30\n",
            "95/95 [==============================] - 121s 1s/step - loss: 6.8723 - acc: 0.0040\n",
            "Epoch 3/30\n",
            "95/95 [==============================] - 124s 1s/step - loss: 6.7563 - acc: 0.0063\n",
            "Epoch 4/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 6.5437 - acc: 0.0152\n",
            "Epoch 5/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 6.1702 - acc: 0.0351\n",
            "Epoch 6/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 5.6742 - acc: 0.0734\n",
            "Epoch 7/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 5.0337 - acc: 0.1485\n",
            "Epoch 8/30\n",
            "95/95 [==============================] - 123s 1s/step - loss: 4.3479 - acc: 0.2312\n",
            "Epoch 9/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 3.8381 - acc: 0.3066\n",
            "Epoch 10/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 3.2703 - acc: 0.3907\n",
            "Epoch 11/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 2.8998 - acc: 0.4545\n",
            "Epoch 12/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 2.4336 - acc: 0.5266\n",
            "Epoch 13/30\n",
            "95/95 [==============================] - 123s 1s/step - loss: 2.1799 - acc: 0.5759\n",
            "Epoch 14/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 1.9185 - acc: 0.6011\n",
            "Epoch 15/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 1.6878 - acc: 0.6404\n",
            "Epoch 16/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 1.4955 - acc: 0.6920\n",
            "Epoch 17/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 1.2782 - acc: 0.7235\n",
            "Epoch 18/30\n",
            "95/95 [==============================] - 124s 1s/step - loss: 1.1844 - acc: 0.7433\n",
            "Epoch 19/30\n",
            "95/95 [==============================] - 121s 1s/step - loss: 1.0394 - acc: 0.7665\n",
            "Epoch 20/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.9012 - acc: 0.7985\n",
            "Epoch 21/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.7933 - acc: 0.8247\n",
            "Epoch 22/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.6935 - acc: 0.8379\n",
            "Epoch 23/30\n",
            "95/95 [==============================] - 123s 1s/step - loss: 0.6481 - acc: 0.8449\n",
            "Epoch 24/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.5700 - acc: 0.8614\n",
            "Epoch 25/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.5197 - acc: 0.8756\n",
            "Epoch 26/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.5266 - acc: 0.8789\n",
            "Epoch 27/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.4636 - acc: 0.8836\n",
            "Epoch 28/30\n",
            "95/95 [==============================] - 123s 1s/step - loss: 0.4102 - acc: 0.9001\n",
            "Epoch 29/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.3727 - acc: 0.9067\n",
            "Epoch 30/30\n",
            "95/95 [==============================] - 120s 1s/step - loss: 0.3855 - acc: 0.9077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f36193c2b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LQMSUY5tWkG"
      },
      "source": [
        "##Saving the model using the HDF5 standard\r\n",
        "model.save('my_final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}